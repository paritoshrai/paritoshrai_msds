{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "palestinian-forth",
   "metadata": {},
   "source": [
    "### 7337 Natural Language Processing Home Work 2 Paritosh Rai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-brass",
   "metadata": {},
   "source": [
    "#### 1.\tIn Python, create a method for scoring the vocabulary size of a text, and normalize the score from 0 to 1. It does not matter what method you use for normalization as long as you explain it in a short paragraph. (Various methods will be discussed in the live session.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "special-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NLTX and othee libraries\n",
    "import nltk\n",
    "# urllib to get info from url. \n",
    "import urllib.request\n",
    "from urllib import request\n",
    "#from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import matplotlib as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import requests\n",
    "import urllib.request\n",
    "#from nltk import word_tokenize\n",
    "# Ref: https://www.guru99.com/accessing-internet-data-with-python.html#:~:text=1%20Call%20the%20read%20function%20on%20the%20webURL,It%20will%20print%20the%20data%20into%20HTML%20format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-anime",
   "metadata": {},
   "source": [
    "## Creat a Function to Read url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "through-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to read data from url\n",
    "def read_url(url):\n",
    "    text = urllib.request.urlopen(url)\n",
    "    data = text.read().decode('utf8')\n",
    "    #print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-resort",
   "metadata": {},
   "source": [
    "### Create a function to Calculate Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "floppy-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to count number of words in the document \n",
    "def word_count(data):\n",
    "    #we will first strip out all non-alpha characters;\n",
    "    #then we will convert the text to lower case;\n",
    "    #then we will count the distinct words\n",
    "    words = nltk.word_tokenize(data)\n",
    "    words=[word.casefold() for word in words if word.isalpha()] # ignore cases when comparing\n",
    "    wc_ln=len(words)\n",
    "    return wc_ln\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-flight",
   "metadata": {},
   "source": [
    "### Create a function to Calculate unique Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "turkish-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to get the vocabulary (unique words) in the document \n",
    "def vocabulary_count(data):\n",
    "    #we will first strip out all non-alpha characters;\n",
    "    #then we will convert the text to lower case;\n",
    "    #then we will count the distinct words\n",
    "    words = nltk.word_tokenize(data)\n",
    "    words=[word.casefold() for word in words if word.isalpha()] # ignore cases when comparing\n",
    "    vc_ln=len(set(words)) # count distinct words\n",
    "    return vc_ln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-montana",
   "metadata": {},
   "source": [
    "### Create a Function to Normalize 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "subject-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to normalize the vocabulary (unique words) score in the document\n",
    "# score is normalized by dividing unique words by total number of words\n",
    "def normalized_score(data):\n",
    "    # we will divde unique words by total number of words\n",
    "    nor_score = vocabulary_count(data)/word_count(data)\n",
    "    return nor_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-making",
   "metadata": {},
   "source": [
    "### Create a Function to Normalize 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "alike-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method to get the Vocab Size and normalize the score\n",
    "\n",
    "def n_vocab_size(*arg):\n",
    "    vocab_size = np.array([])\n",
    "    vocab_size_norm = np.array([])\n",
    "    \n",
    "    #### Getting the Vocab Size\n",
    "    for text in arg:\n",
    "        vocab_size = np.append(vocab_size,len(set(text)))\n",
    "    \n",
    "    #### Normalizing using the formula \n",
    "    for vsize in vocab_size:\n",
    "        vocab_size_norm = np.append(vocab_size_norm,(vsize - vocab_size.min()) /\n",
    "                                                    (vocab_size.max() - vocab_size.min()))\n",
    "    \n",
    "    #### Normalizing using sklearn preprocessing \n",
    "    vocab_size_norm_sklearn = minmax_scale(vocab_size, feature_range=(0,1), axis=0)\n",
    "    \n",
    "    return(vocab_size,vocab_size_norm,vocab_size_norm_sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "tested-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data for grade 4th, 5th and 6th\n",
    "#Grade4 book\n",
    "url='https://www.gutenberg.org/files/49339/49339-0.txt'\n",
    "data_4=read_url(url)\n",
    "#Grade5 book\n",
    "url='https://www.gutenberg.org/files/51000/51000-0.txt'\n",
    "data_5=read_url(url)\n",
    "#Grade6 book\n",
    "url='https://www.gutenberg.org/files/36864/36864-0.txt'\n",
    "data_6=read_url(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "regulation-sight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([145., 123., 107.]),\n",
       " array([1.        , 0.42105263, 0.        ]),\n",
       " array([1.        , 0.42105263, 0.        ]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Corpus using three grade book\n",
    "vocab_size = n_vocab_size(data_4, data_5, data_6)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-berry",
   "metadata": {},
   "source": [
    "#### Normalization Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "french-elimination",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Values by using the formula\n",
      "- 1.0\n",
      "- 0.42105263157894735\n",
      "- 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Values by using the formula\", *vocab_size[1],sep='\\n- ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "frozen-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to calculate corpus normalization score\n",
    "def normalized_score_corp(grade):\n",
    "    # we will divde unique words by total number of words\n",
    "    nor_score_grade = vocab_size[1][grade-4]\n",
    "    return nor_score_grade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-montana",
   "metadata": {},
   "source": [
    "#### Normilazion Method 3 (using sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ruled-ivory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Values by using sklearn\n",
      "- 1.0\n",
      "- 0.42105263157894735\n",
      "- 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized Values by using sklearn\", *vocab_size[2],sep='\\n- ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-favorite",
   "metadata": {},
   "source": [
    "#### School Reading By Grades: Fourth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "authorized-pension",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count for School Reading By Grades Fourth Year is: 50603\n",
      "\n",
      "Vocabulary Count for School Reading By Grades Fourth Year is: 6012\n",
      "\n",
      "Normalized in single doc\n",
      "Normalize the score of Vacabulary for School Reading By Grades Fourth Year is:  0.11880718534474241\n",
      "\n",
      "Normalize using corpus made of the books for Grdae 4th,5th and 6th year\n",
      "Normalize 2 the score of Vacabulary for School Reading By Grades Fourth Year is:  1.0\n"
     ]
    }
   ],
   "source": [
    "url='https://www.gutenberg.org/files/49339/49339-0.txt'\n",
    "data_4=read_url(url)\n",
    "print('Word Count for School Reading By Grades Fourth Year is:', word_count(data_4))\n",
    "print('') # line space\n",
    "print ('Vocabulary Count for School Reading By Grades Fourth Year is:',vocabulary_count(data_4))\n",
    "print('') # line space\n",
    "print ('Normalized in single doc')\n",
    "print ('Normalize the score of Vacabulary for School Reading By Grades Fourth Year is: ', normalized_score(data_4))\n",
    "print('')# line space\n",
    "print('Normalize using corpus made of the books for Grdae 4th,5th and 6th year')\n",
    "print ('Normalize 2 the score of Vacabulary for School Reading By Grades Fourth Year is: ', normalized_score_corp(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-kansas",
   "metadata": {},
   "source": [
    "Two normalization methods were calculated. \n",
    "\n",
    "**First Method:** Normalization was done using the respective grade yearbook.  This method was not very effective when the effort is made to compare documents across the corpus. \n",
    "\n",
    "**Second Method:** In the second method, normalization was derived across the corpus of grade years 4,5, and 6. We will compare these documents' difficulty levels with each other, so the normalized value derived from the 2nd method will be used.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-judge",
   "metadata": {},
   "source": [
    "#### School Reading By Grades: Fifth Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "electronic-trinidad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count for School Reading By Grades Fifth Year is: 45103\n",
      "\n",
      "Vocabulary Count for School Reading By Grades Fifth Year is: 6839\n",
      "\n",
      "Normalized in single doc\n",
      "Normalize the score of Vacabulary for School Reading By Grades Fifth Year is:  0.15163071192603597\n",
      "\n",
      "Normalize using corpus made of the books for Grdae 4th,5th and 6th year\n",
      "Normalize 2 the score of Vacabulary for School Reading By Grades Fifth Year is:  0.42105263157894735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url='https://www.gutenberg.org/files/51000/51000-0.txt'\n",
    "data_5=read_url(url)\n",
    "print('Word Count for School Reading By Grades Fifth Year is:', word_count(data_5))\n",
    "print('') # line space\n",
    "print ('Vocabulary Count for School Reading By Grades Fifth Year is:',vocabulary_count(data_5))\n",
    "print('') # line space\n",
    "print('Normalized in single doc')\n",
    "print ('Normalize the score of Vacabulary for School Reading By Grades Fifth Year is: ', normalized_score(data_5))\n",
    "print('') # line space\n",
    "print('Normalize using corpus made of the books for Grdae 4th,5th and 6th year')\n",
    "print ('Normalize 2 the score of Vacabulary for School Reading By Grades Fifth Year is: ', normalized_score_corp(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-values",
   "metadata": {},
   "source": [
    "#### School Reading By Grades: Sixth Year¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "recent-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count for School Reading By Grades Sixth Year is: 60017\n",
      "\n",
      "Vocabulary Count for School Reading By Grades Sixth Year is: 8137\n",
      "\n",
      "Normalized in single doc\n",
      "Normalize the score of Vacabulary for School Reading By Grades Sixth Year is (Normlize 1):  0.1355782528283653\n",
      "\n",
      "Normalize using corpus mode of the books for Grdae 4th,5th and 6th year\n",
      "Normalize 2 the score of Vacabulary for School Reading By Grades Fifth Year is:  0.0\n"
     ]
    }
   ],
   "source": [
    "url='https://www.gutenberg.org/files/36864/36864-0.txt'\n",
    "data_6=read_url(url)\n",
    "print('Word Count for School Reading By Grades Sixth Year is:', word_count(data_6))\n",
    "print('') # line space\n",
    "print ('Vocabulary Count for School Reading By Grades Sixth Year is:',vocabulary_count(data_6))\n",
    "print('') # line space\n",
    "print('Normalized in single doc')\n",
    "print ('Normalize the score of Vacabulary for School Reading By Grades Sixth Year is (Normlize 1): ', normalized_score(data_6))\n",
    "print('') # line space\n",
    "print('Normalize using corpus mode of the books for Grdae 4th,5th and 6th year')\n",
    "print ('Normalize 2 the score of Vacabulary for School Reading By Grades Fifth Year is: ', normalized_score_corp(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-economy",
   "metadata": {},
   "source": [
    "#### 2.\tAfter consulting section 3.2 in chapter 1 of Bird-Klein, create a method for scoring the long-word vocabulary size of a text, and likewise normalize (and explain) the scoring as in step 1 above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-newspaper",
   "metadata": {},
   "source": [
    "### Define Function to Count Long Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "alive-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to count long words\n",
    "# give the name of data and length of long word\n",
    "def count_long_word(data,n):\n",
    "    #tokenize the data set\n",
    "    word = nltk.word_tokenize(data)\n",
    "    #keep only apphabets\n",
    "    words=[word.casefold() for word in word if word.isalpha()]\n",
    "    #remove the duplicate\n",
    "    words = set(words)\n",
    "    #find long words\n",
    "    long_words = [w for w in words if len(w) > n]\n",
    "    #count number of long words\n",
    "    lw_len=len(long_words)\n",
    "    return lw_len\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-superintendent",
   "metadata": {},
   "source": [
    "### Define Function to Normalize Long Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "enclosed-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to normalize the long vocabulary (unique words) score in the document\n",
    "# score is normalized by dividing number of long unique words by total number of unique words\n",
    "def normalized_longword_score(data,n):\n",
    "    # we will divde unique words by total number of words\n",
    "    nor_lw_score = count_long_word(data,n)/vocabulary_count(data)\n",
    "    return nor_lw_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-phenomenon",
   "metadata": {},
   "source": [
    "#### Long Word Count and Normalize Long Word Grade 6\n",
    "Word length of 15 was consered as  long word  as Natural Language Processing with Python by Steven Bird, Ewan Klein, Edward Loper in section 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "daily-yahoo",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Long Vocabulary for the School Reading By Grades Six is: 6\n",
      "Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grades Six is: 0.000737372496005899\n"
     ]
    }
   ],
   "source": [
    "# Long word was assumed to be weith with eight (15) letters\n",
    "print('Count of Long Vocabulary for the School Reading By Grades Six is:', count_long_word(data_6,15))\n",
    "print('Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grades Six is:', normalized_longword_score(data_6,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "induced-australian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Long Vocabulary for the School Reading By Grades Six is: 89\n",
      "Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grades Six is: 0.010937692024087502\n"
     ]
    }
   ],
   "source": [
    "# As longword count was only 6, with word length of 15, after few attempts adjusted the longword length to 12\n",
    "print('Count of Long Vocabulary for the School Reading By Grades Six is:', count_long_word(data_6,12))\n",
    "print('Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grades Six is:', normalized_longword_score(data_6,12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-korea",
   "metadata": {},
   "source": [
    "#### Long Word Count and Normalize Long Word Grade 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "solid-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Long Vocabulary for the School Reading By Grades five year with word lenght 12: 56\n",
      "Count of Long Vocabulary for the School Reading By Grades five uear is: 147\n",
      "Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grades five Year is: 0.021494370522006142\n"
     ]
    }
   ],
   "source": [
    "# Long word was assumed to be weith with ten (10) letters\n",
    "print('Count of Long Vocabulary for the School Reading By Grades five year with word lenght 12:', count_long_word(data_5,12))\n",
    "print('Count of Long Vocabulary for the School Reading By Grades five uear is:', count_long_word(data_5,11))\n",
    "print('Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grades five Year is:', normalized_longword_score(data_5,11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-reserve",
   "metadata": {},
   "source": [
    "#### Long Word Count and Normalize Long Word Grade 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "approximate-white",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of Long Vocabulary for the School Reading By Grades four year with word lenght 12: 41\n",
      "Count of Long vocabulary for the School Reading By Grades four Year is: 246\n",
      "Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade four Year is: 0.04091816367265469\n"
     ]
    }
   ],
   "source": [
    "# Long word was assumed to be weith with ten (10) letters\n",
    "print('Count of Long Vocabulary for the School Reading By Grades four year with word lenght 12:', count_long_word(data_4,12))\n",
    "print('Count of Long vocabulary for the School Reading By Grades four Year is:', count_long_word(data_4,10))\n",
    "print('Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade four Year is:', normalized_longword_score(data_4,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-topic",
   "metadata": {},
   "source": [
    "The above function was used to find the total number of long words used in grade-level books. The function is created to calculate the Normalized Long Vocabulary. We started with a longword length of 15 as per guidance from  **\"Natural Language Processing with Python\" by Steven Bird, Ewan Klein, Edward Loper in section 1.3**. However, we could find only six words and normalize value was very low as well. After a few iterations, longword sizes of 12,11 and 10 were chosen for 6th,5th, and a 4th-grade year respectively. \n",
    "\n",
    "To normalize the outcome of long words, the count of long words in the respective grade year book was divided by the number of unique words in the respective book. \n",
    "\n",
    "It was observed that long word counts were 89, 56, and 41for the 6th,5th, and 4th-grade year, respectively, when word size was 12. The long word count was aligned with expectation. As the grade level goes up, the number of long words is expected to go up. \n",
    "\n",
    "Hower to align the difficulty level word count length was reduced by one as grade year decrease. The assumption is that as readers go in higher grade, year-long word length should also increase (how much is debatable, we reduced the count to increase by one in the exercise). However, the function was built with the flexibility to adjust if needed. After a few iterations, longword sizes of 12,11, and 10 were chosen for 6th,5th, and 4th-grade yeara, respectively.\n",
    "\n",
    "**Conclusion:** Outcome was not very aligned with expectations. We expected longword count and normalized longword to coverage with the adjustment of the length of the longword, but the number of long words and the normalized count went in reverse order.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-feelings",
   "metadata": {},
   "source": [
    "#### 3.\tNow create a “text difficulty score” by combining the lexical diversity score from homework 1, and your normalized score of vocabulary size and long-word vocabulary size, in equal weighting. Explain what you see when this score is applied to same graded texts you used in homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "overhead-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate Lexical Diversity\n",
    "def lex_div(data):\n",
    "    ld = len(data)/len(set(data))\n",
    "    return ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "perceived-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3396.2897196261683"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexical Diversity for grade 6 years\n",
    "lex_div6=lex_div(data_6)\n",
    "lex_div6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "multiple-antibody",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2210.878048780488"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexical Diversity for grade 5 years\n",
    "lex_div5=lex_div(data_5)\n",
    "lex_div5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "about-provider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2168.8137931034485"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexical Diversity for grade 4 years\n",
    "lex_div4=lex_div(data_4)\n",
    "lex_div4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-patient",
   "metadata": {},
   "source": [
    "**Lexical Diversity** is the number of times each vocabulary item appears in the text on average in a given book, text, or doc. Higher the number more the repetition. Based on the Lexical Diversity Score, we can say words are repeated more in the 6th-grade year book than the 5th-grade year book, and the 5th-grade year have more repetition of words than the 4th. However, we expected to see less repetition as the grade goes up as new words will be introduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-fleece",
   "metadata": {},
   "source": [
    "### Create Function to Calculate Text Difficulty Score\n",
    "Three factors will be taken into account the difficulty score of the respective Score:\n",
    "\n",
    "**Lexical Diversity:** Number of times each vocabulary item appears in the text on average\n",
    "\n",
    "**Normalized Score for vocabulary size:** Long word score count was normalized across the corpus to calculated to bring in uniformity across the three books. \n",
    "\n",
    "**Long Word Vaculabury Size:** Long word vocabulary size was adjusted to account for the grade year level. A longword size of 12,11, and 10 was chosen for the 6th,5th, and 4th-grade year, respectively.\n",
    "\n",
    "**Difficulty Score:** Difficulty Score was calculated taking three factors into account Lexical Diversity, Normalized Score for Vocabulary Size, and Long Word Vaculabury Size. \n",
    "\n",
    "Following is the relationship of these measures with the difficulty score:\n",
    "\n",
    "**Lexical Score:** Higher the Lexical Score, there is more repetition of words, i.e., fewer new words, so the difficulty level is lower, i.e., Lexical score and difficulty level are inversely related. \n",
    " \n",
    "***Normalized Score for Vocabulary Size:** Vocabe size was normalized across the corpus (i.e., all three grade year books). ThisNormilization was carried out to ensure they are measured on the same scale. Normalized values were higher for grade year 4 (i.e., 1) and lowest for grade year 6 (i.e., 0), so higher value for lower grade. \n",
    "\n",
    "**Long Word Vocabulary Size:**  Longer the Vocabulary higher the difficulty score. So Difficulty Score and Vocabulary Size should be directly related. We have normalized the value based on the respective document and adjusted the length based on grade year. Higher the grade year, longer the word. \n",
    "\n",
    "**To sumaraize:**\n",
    "\n",
    "* Difficulty Score => Inversely Propstional( Lexical Diversity)\n",
    "\n",
    "* Difficulty Score => Directly Propostion (Normalized Score for Vocabulary Size)\n",
    "\n",
    "* Difficulty Score => Inversely Propstional (Long Word Vocabulary Size)\n",
    "\n",
    "The difficulty level function was created by subtracting normalized_score_corp(grade) from normalized longword Score. The difference is multiplied by 1,000,000 to deal with decimal values. The product of 1 million and difference is squared, and then square root was applied to eliminate negative values. The numerator was divide by Lexical Diversity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "democratic-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created function to calculate text difficulty score\n",
    "# function for difficulty score was calculated by multiplying normalized_longeword_score (adjsuted for grader level) with 1,000,000 and devicing them by lexical diversity and \n",
    "# long word normilozation were be adjusted by changing the length of the word for respective grades\n",
    "def text_difficulty_score(data,n,grade):\n",
    "    text_dif_score = (((normalized_longword_score(data,n) - normalized_score_corp(grade)) *1000000/ lex_div(data))**2)**0.5\n",
    "    return text_dif_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "metallic-animation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Diversity of School Reading School Reading By Grades Sixth Year is: 3396.2897196261683\n",
      "Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade Sixth Year is: 0.21334644217770676\n",
      "Text Difficulty Score of text for the School Reading By Grade Sixth Year is: 3.2204826228109362\n"
     ]
    }
   ],
   "source": [
    "# text difficulty level calcualted using same text of eight(8) for all grade levels\n",
    "# if the length of long words were kept same difficulty level is expected to go up.\n",
    "# as the books in higher grades will have more diverse words\n",
    "print('Lexical Diversity of School Reading School Reading By Grades Sixth Year is:', lex_div(data_6))\n",
    "print('Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade Sixth Year is:', normalized_longword_score(data_6,8))\n",
    "print('Text Difficulty Score of text for the School Reading By Grade Sixth Year is:', text_difficulty_score(data_6,12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "gorgeous-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Diversity of School Reading School Reading By Grades Fiveth Year is: 2210.878048780488\n",
      "Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade Fivth Year is: 0.18862406784617633\n",
      "Text Difficulty Score of text for the School Reading By Grade Fiveth Year is: 180.72379038605771\n"
     ]
    }
   ],
   "source": [
    "# text difficulty level calcualted using same text of eight(8) for all grade levels\n",
    "# if the length of long words were kept same difficulty level is expected to go up.\n",
    "# as the books in higher grades will have more diverse words\n",
    "print('Lexical Diversity of School Reading School Reading By Grades Fiveth Year is:', lex_div(data_5))\n",
    "print('Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade Fivth Year is:', normalized_longword_score(data_5,8))\n",
    "print('Text Difficulty Score of text for the School Reading By Grade Fiveth Year is:', text_difficulty_score(data_5,11,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "matched-gothic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Diversity of School Reading School Reading By Grades Fourth Year is: 2168.8137931034485\n",
      "Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade Fourth Year is: 0.17980705256154358\n",
      "Text Difficulty Score of text for the School Reading By Grade Fourth Year is: 442.21492844480395\n"
     ]
    }
   ],
   "source": [
    "# text difficulty level calcualted using same text of eight(8) for all grade levels\n",
    "# if the length of long words were kept same difficulty level is expected to go up.\n",
    "# as the books in higher grades will have more diverse words\n",
    "print('Lexical Diversity of School Reading School Reading By Grades Fourth Year is:', lex_div(data_4))\n",
    "print('Normalize Long Vocabulary the of Long vocabulary for the School Reading By Grade Fourth Year is:', normalized_longword_score(data_4,8))\n",
    "print('Text Difficulty Score of text for the School Reading By Grade Fourth Year is:', text_difficulty_score(data_4,10,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-drove",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "The difficulty score was inconsistent with the expectation. Grader 4 had the highest score of ~442, and Grade 6 was ~3. Whereas Grade 5 was in the middle at 180. \n",
    "However, the Lexical Score was also in reverse order, i.e., higher Lexical Score for the higher grade. So created Difficulty Score is incorrect; somehow, it did not align with the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-integral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
