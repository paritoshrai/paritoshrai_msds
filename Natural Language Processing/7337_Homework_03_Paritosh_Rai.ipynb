{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acute-expansion",
   "metadata": {},
   "source": [
    "### Homework 03 Paritosh Rai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-doctrine",
   "metadata": {},
   "source": [
    "#### 1.\tCompare your given name with your nickname (if you donâ€™t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "#### a.\tWhat is the edit distance between your nickname and your given name?\n",
    "#### b.\tWhat is the percentage string match between your nickname and your given name?\n",
    "#### Show your work for both calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-hardware",
   "metadata": {},
   "source": [
    "#####  Given Name: Paritosh\n",
    "\n",
    "##### Nick Name: Pintu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-demonstration",
   "metadata": {},
   "source": [
    "Length of given name Paritosh is 8 and lenght of my nick name Pintu is 5\n",
    "\n",
    "First letter is common i.e. \"P\" so no change rquired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-librarian",
   "metadata": {},
   "source": [
    "#### 1st Method using elif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "informed-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(string1, string2):\n",
    "    \"\"\"Ref: https://bit.ly/2Pf4a6Z\"\"\"\n",
    "\n",
    "    if len(string1) > len(string2):\n",
    "        difference = len(string1) - len(string2)\n",
    "        str = string2[:]\n",
    "\n",
    "    elif len(string2) > len(string1):\n",
    "        difference = len(string2) - len(string1)\n",
    "        str = string1[:]\n",
    "\n",
    "    else:\n",
    "        difference = 0\n",
    "        str = string1[:]\n",
    "\n",
    "    \n",
    "    for i in range(len(str)-1):\n",
    "        if string1[i] != string2[i]:\n",
    "            difference += 1\n",
    "\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "union-closing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit Distance between my Nick name Pintu and my given name Paritosh is 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Edit Distance between my Nick name Pintu and my given name Paritosh is \"+ str(edit_distance(\"Pintu\",\"Paritosh\" )))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-hartford",
   "metadata": {},
   "source": [
    "#### 2nd Method Using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dirty-textbook",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit Distance between my Nick name Pintu and my given name Paritosh is 6\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# string decleration\n",
    "source = 'Pintu'\n",
    "target = 'Paritosh'\n",
    "#distance calculation\n",
    "edit_distance_nltk=nltk.edit_distance(source , target)\n",
    "edit_distance_nltk\n",
    "print(\"Edit Distance between my Nick name Pintu and my given name Paritosh is \" + str(edit_distance_nltk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-alexander",
   "metadata": {},
   "source": [
    "#### b. What is the percentage string match between your nickname and your given name?\n",
    "#### Show your work for both calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "forbidden-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"https://www.geeksforgeeks.org/python-count-the-number-of-matching-characters-in-a-pair-of-string/\"\"\"\n",
    "\n",
    "def count(str1 ,str2) :\n",
    "    # store unique letters from the string1\n",
    "    #\n",
    "    set_string1 = set(str1)\n",
    "  \n",
    "    # store unique letters from the string1\n",
    "    set_string2 = set(str2)\n",
    "  \n",
    "    # using (&) intersection mathematical operation on sets\n",
    "   \n",
    "    matched_characters = set_string1 & set_string2\n",
    "    \n",
    "    # double the number of match characters and devide by sum of length of both names\n",
    "    percent_match = 100 * 2*(len(matched_characters))/(len(str1) + len(str2))\n",
    "      \n",
    "    # printing the length of matched_characters set\n",
    "    print(\"No. of matching characters are : \" + str(len(matched_characters)) )\n",
    "    print(\"Total number of characters in Given_Name + Nick_Name : \" ,(len(str1) + len(str2)))\n",
    "    print(\"Percentage of matching characters are : \" + str(percent_match) + \" %\") # change float to string\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "committed-genre",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of matching characters are : 3\n",
      "Total number of characters in Given_Name + Nick_Name :  13\n",
      "Percentage of matching characters are : 46.15384615384615 %\n"
     ]
    }
   ],
   "source": [
    "no_of_match = count(\"Pintu\", \"Paritosh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-sense",
   "metadata": {},
   "source": [
    "#### 2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-router",
   "metadata": {},
   "source": [
    "I picked \"Harry Potter and the Sorcerer's Stone\" and picked few sentences from the book. I asked my daughter to guess the book after removing the stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "employed-banner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\parit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Dursley', 'stood', 'rooted', 'spot', '.', 'He', 'hugged', 'complete', 'stranger', '.', 'He', 'thought', 'called', 'Muggle', ',', 'whatever', '.', 'He', 'rattled', '.', 'He', 'hurried', 'car', 'set', 'home', ',', 'hoping', 'imagining', 'things', ',', 'never', 'hoped', ',', \"n't\", 'approve', 'imagination']\n"
     ]
    }
   ],
   "source": [
    "'''https://stackabuse.com/removing-stop-words-from-strings-in-python/#usingpythonsnltklibrary'''\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords # import stop words form NLTK\n",
    "nltk.download('stopwords') # download stop words\n",
    "from nltk.tokenize import word_tokenize # import tokenizer\n",
    "\n",
    "part_book= \"Mr. Dursley stood rooted to the spot. He had been hugged by a complete stranger. He also thought he had been called a Muggle, whatever that was. He was rattled. He hurried to his car and set off for home, hoping he was imagining things, which he had never hoped before, because he didn't approve of imagination\"\n",
    "text_tokens = word_tokenize(part_book)\n",
    "#remove stop words from the sentence\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()] \n",
    "print(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-eligibility",
   "metadata": {},
   "source": [
    "**Which book the words are from?**\n",
    "\n",
    "She guessed the book correctly on the first try, \"Harry Potter.\" \n",
    "\n",
    "**What did he or she guess?**\n",
    "Then I asked her which book of Harry Potter? She respounded, \"Harry Potter and the Sorcerer's Stone.\"  That was the correct answer. \n",
    "\n",
    "**Explain why you think you friend either was or was not able to guess the book from hearing the list of words.**\n",
    "\n",
    "I asked her how she guessed?  She said from Mr. Dursley (uncle of Harry Potter) and the word Muggle (word used for human in the book). That was aligned with my guess. \n",
    "\n",
    "I further asked her, but these might be appearing in all four or five books? She said Mr. Dursley appears in 1st two books only after that there is no mention, and she kind of guessed it is 1st one. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-syracuse",
   "metadata": {},
   "source": [
    "#### 3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-salem",
   "metadata": {},
   "source": [
    "#### Method 1 : With Tokenizer with Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "italic-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''https://www.datacamp.com/community/tutorials/stemming-lemmatization-python'''\n",
    "\n",
    "import nltk\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize # tokenize word and sentence\n",
    "\n",
    "#stem each word in the sentence and return a combined sentence.\n",
    "# define a function to stem \n",
    "def stemSentence(sentence): \n",
    "    token_words=word_tokenize(sentence) # tokenize each word\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    #break each word of sentence,stem and add to sentence\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(ps.stem(word)) # stem each word\n",
    "        stem_sentence.append(\" \") # add stem words to sentence\n",
    "    return \"\".join(stem_sentence) # create sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sealed-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr. dursley stood root to the spot . he had been hug by a complet stranger . he also thought he had been call a muggl , whatev that wa . he wa rattl . he hurri to hi car and set off for home , hope he wa imagin thing , which he had never hope befor , becaus he did n't approv of imagin \n"
     ]
    }
   ],
   "source": [
    "x=stemSentence(\"Mr. Dursley stood rooted to the spot. He had been hugged by a complete stranger. He also thought he had been called a Muggle, whatever that was. He was rattled. He hurried to his car and set off for home, hoping he was imagining things, which he had never hoped before, because he didn't approve of imagination\")\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "vanilla-binding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 66 words.\n"
     ]
    }
   ],
   "source": [
    "# count total number of words in the string\n",
    "# initialize string\n",
    "\n",
    "# default separator: space\n",
    "no_words_in_text = len(x.split())\n",
    "\n",
    "print(\"There are \" + str(no_words_in_text) + \" words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-philosophy",
   "metadata": {},
   "source": [
    " #### Valid morphological roots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "wrong-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function with nltk corpus \n",
    "import nltk\n",
    "def valid_word(sent):\n",
    "    words = set(nltk.corpus.words.words()) \n",
    "    return \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
    "\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "mobile-listing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". stood rooted to the spot . He had been by a complete stranger . He also thought he had been a , whatever that was . He was rattled . He hurried to his car and set off for home , he was , which he had never hoped before , because he ' t approve of imagination\n"
     ]
    }
   ],
   "source": [
    "valid_text= valid_word(valid_word(part_book)) # run with text of book\n",
    "no_of_valid_text = len(valid_text.split()) # count number of token with punchuation\n",
    "print(valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "seventh-bones",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are valid morphological roots 59 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are valid morphological roots \" + str(no_of_valid_text) + \" words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-maintenance",
   "metadata": {},
   "source": [
    "#### Percentage of Valid Morpholigical roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "assisted-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of valid morphological roots is 89.39393939393939 %.\n"
     ]
    }
   ],
   "source": [
    "prct_valid_morph =100 *(no_of_valid_text)/(no_words_in_text) #calculate percentage by number of valid text and no of total words\n",
    "print(\"Percent of valid morphological roots is \" + str(prct_valid_morph) + \" %.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-weekly",
   "metadata": {},
   "source": [
    "The total number of words (including punctuation) with PorterStemmer is 66, and the number of words (including punctuation) with valid Morphological is 59. The percentage of the valid morphological root is 89%. This is an indicator that PorterStemmer is very effective in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-death",
   "metadata": {},
   "source": [
    " #### Method 2 without Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "excessive-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize # tokenize word and sentence\n",
    "from nltk.tokenize import RegexpTokenizer # remove punchuation\n",
    "\n",
    "#stem each word in the sentence and return a combined sentence.\n",
    "# define a function to stem without punchuation\n",
    "def stemSentence_wop(sentence):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') # remove punctuation or filter only word\n",
    "    token_words=tokenizer.tokenize(sentence) # tokenize each word remove punctuation\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    #break each word of sentence,stem and add to sentence\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(ps.stem(word)) # stem each word using Porter Stemmer\n",
    "        stem_sentence.append(\" \") # add stem words to sentence\n",
    "    return \"\".join(stem_sentence) # create sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "hungry-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr dursley stood root to the spot he had been hug by a complet stranger he also thought he had been call a muggl whatev that wa he wa rattl he hurri to hi car and set off for home hope he wa imagin thing which he had never hope befor becaus he didn t approv of imagin \n"
     ]
    }
   ],
   "source": [
    "# print the text after applying Porter Stemmer \n",
    "x_wop=stemSentence_wop(\"Mr. Dursley stood rooted to the spot. He had been hugged by a complete stranger. He also thought he had been called a Muggle, whatever that was. He was rattled. He hurried to his car and set off for home, hoping he was imagining things, which he had never hoped before, because he didn't approve of imagination\")\n",
    "\n",
    "print(x_wop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "thrown-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58 words (tokens) without punchuation.\n"
     ]
    }
   ],
   "source": [
    "# count total number of words in the string\n",
    "# initialize string\n",
    "\n",
    "# default separator: space\n",
    "no_words_in_text_wop = len(x_wop.split()) # count the number of words/token\n",
    "\n",
    "print(\"There are \" + str(no_words_in_text_wop) + \" words (tokens) without punchuation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-paint",
   "metadata": {},
   "source": [
    "#### Valid morphological roots without Punchuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "positive-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to stem using nltk corpus and remove punchuation\n",
    "import nltk\n",
    "def valid_word_wop(sent):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') # remove punchuation and all only word\n",
    "    words = set(nltk.corpus.words.words()) # pick words only from nltk corpus\n",
    "    return \" \".join(w for w in tokenizer.tokenize(sent) \\\n",
    "\n",
    "         if w.lower() in words or not w.isalpha())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dominant-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stood rooted to the spot He had been by a complete stranger He also thought he had been a whatever that was He was rattled He hurried to his car and set off for home he was which he had never hoped before because he t approve of imagination\n"
     ]
    }
   ],
   "source": [
    "valid_text_wop= valid_word(valid_word_wop(part_book)) # run the function to print \n",
    "no_of_valid_text_wop = len(valid_text_wop.split()) #count the length of stem after removing punchuation and keeping valid words\n",
    "print(valid_text_wop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "capital-calgary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are valid morphological roots without punchuation 49 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are valid morphological roots without punchuation \" + str(no_of_valid_text_wop) + \" words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-converter",
   "metadata": {},
   "source": [
    "#### Percentage of Valid Morpholigical roots without Punchuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "coastal-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of valid morphological roots is 84.48275862068965 %.\n"
     ]
    }
   ],
   "source": [
    "#calculate the percentage of valid stem words without puction and stem words usinger Porter Stemmer\n",
    "prct_valid_morph_wop =100 *(no_of_valid_text_wop)/(no_words_in_text_wop)\n",
    "print(\"Percent of valid morphological roots is \" + str(prct_valid_morph_wop) + \" %.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-arabic",
   "metadata": {},
   "source": [
    "Valid morphological without punctuation is little lower (84%) compared to with punctuation (89%). This is expected outcome. Depending on what we are trying do with text stemming, both have their utility. In normally validated text without punctuation make more sense to me. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
