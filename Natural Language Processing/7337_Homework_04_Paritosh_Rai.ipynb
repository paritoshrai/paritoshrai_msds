{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP - Homework 4\n",
    "### Paritosh Rai¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "#### a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devinci's capable Hatchet frame is paired with Shimano's workhorse 105 drivetrain for a durable bike ready to handle the rough roads.\n"
     ]
    }
   ],
   "source": [
    "# long sentence\n",
    "l_sent=  \"Devinci's capable Hatchet frame is paired with Shimano's workhorse 105 drivetrain for a durable bike ready to handle the rough roads.\"\n",
    "print(l_sent) # print input statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech: [('Devinci', 'NNP'), (\"'s\", 'POS'), ('capable', 'JJ'), ('Hatchet', 'NNP'), ('frame', 'NN'), ('is', 'VBZ'), ('paired', 'VBN'), ('with', 'IN'), ('Shimano', 'NNP'), (\"'s\", 'POS'), ('workhorse', 'NN'), ('105', 'CD'), ('drivetrain', 'NN'), ('for', 'IN'), ('a', 'DT'), ('durable', 'JJ'), ('bike', 'NN'), ('ready', 'JJ'), ('to', 'TO'), ('handle', 'VB'), ('the', 'DT'), ('rough', 'JJ'), ('roads', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "'''https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b'''\n",
    "\n",
    "import nltk # import nltk\n",
    "l_tokens = nltk.word_tokenize(l_sent) # tokenize the sentence\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(l_tokens)) # find part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. 1b) Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small centence\n",
    "s_sent1 ='There are no easy solution.' # First Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech: [('There', 'EX'), ('are', 'VBP'), ('no', 'DT'), ('easy', 'JJ'), ('solution', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk # import nltk\n",
    "s_tokens1 = nltk.word_tokenize(s_sent1) # tokenize the First sentence\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(s_tokens1)) # find part of speech of frist Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly classified the POS in first short sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small centence\n",
    "s_sent2 ='my cat is pink.'# Second sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech: [('my', 'PRP$'), ('cat', 'NN'), ('is', 'VBZ'), ('pink', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk # import nltk\n",
    "s_tokens2 = nltk.word_tokenize(s_sent2) # tokenize the second sentence\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(s_tokens2)) # find part of speech for third sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly classified the POS in second short sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small Sentence\n",
    "s_sent3 ='color are colorful.' # Third sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech: [('color', 'NN'), ('are', 'VBP'), ('colorful', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk # import nltk\n",
    "s_tokens = nltk.word_tokenize(s_sent3) # tokenize the third sentence\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(s_tokens)) # find part of speech for third sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctly classified the POS in third short sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small centence\n",
    "s_sent4 ='The watch watches.' # Fourth Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech: [('The', 'DT'), ('watch', 'NN'), ('watches', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk # import nltk\n",
    "s_tokens = nltk.word_tokenize(s_sent4) # tokenize the fourth sentence\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(s_tokens)) # find part of speech of fourth sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fourth short sentence \"watches\" should be verb but it was classfiled as plural noun.\n",
    "\n",
    "#### Checked four different short sentences. Part of speech classification worked fine for three short sentences. However, we had challenge with fourth sentence. If sentence is straight and simple nltk classify the part of speech correctly even in case of small sentences. However, if sentence is complex or twisted then nltk may have challenge correctly identify the part of speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "a.\tDoes it produce the same or different output?\n",
    "b.\tExplain any differences as best you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy # import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm') # load model for the English language "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Long Sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devinci PROPN\n",
      "'s PART\n",
      "capable ADJ\n",
      "Hatchet PROPN\n",
      "frame NOUN\n",
      "is AUX\n",
      "paired VERB\n",
      "with ADP\n",
      "Shimano PROPN\n",
      "'s PART\n",
      "workhorse ADJ\n",
      "105 NUM\n",
      "drivetrain NOUN\n",
      "for ADP\n",
      "a DET\n",
      "durable ADJ\n",
      "bike NOUN\n",
      "ready ADJ\n",
      "to PART\n",
      "handle VERB\n",
      "the DET\n",
      "rough ADJ\n",
      "roads NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# long sentense\n",
    "l_sent=  \"Devinci's capable Hatchet frame is paired with Shimano's workhorse 105 drivetrain for a durable bike ready to handle the rough roads.\"\n",
    "\n",
    "\n",
    "doc = nlp(l_sent)\n",
    "# look at each work and break in each entity and PoS for entity \n",
    "for ent in doc:\n",
    "      print(ent, ent.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of Speech of long sentence (l_sent) using nltk in question 1a above: [('Devinci', 'NNP'), (\"'s\", 'POS'), ('capable', 'JJ'), ('Hatchet', 'NNP'), ('frame', 'NN'), **('is', 'VBZ')**, ('paired', 'VBN'), ('with', 'IN'), ('Shimano', 'NNP'), (\"'s\", 'POS'), **('workhorse', 'NN'), ('105', 'CD')**, ('drivetrain', 'NN'), ('for', 'IN'), ('a', 'DT'), ('durable', 'JJ'), ('bike', 'NN'), ('ready', 'JJ'), ('to', 'TO'), ('handle', 'VB'), ('the', 'DT'), ('rough', 'JJ'), ('roads', 'NNS'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the Part of Speech (PoS) matches usining NLTK and spacy. There were words show different PoS. Few of the difference are highligted in bold.  \n",
    "\n",
    "**is:** is can be both VBZ (verb, 3rd person sing)and AUX so it okay way nltk and spacy. We can understand why they will pick on or other column.\n",
    "\n",
    "**workhorse:** workhorse is a singular noun is correctly classified by nltk and incorrectly classified by spacy as adjective in the contest. Workhorse some time used as adjective for hardworker as adjective so we understand why nltk cataegorized it as adjective. \n",
    "\n",
    "**105**: 105 is a digit and is classified as CD (cardinal digit - part of speach use to count) by nltk, so we can see why nltk picked 105 as number. However in this contest spacy correctly marked as NN (noun, singular). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Sentence 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There PRON\n",
      "are AUX\n",
      "no DET\n",
      "easy ADJ\n",
      "solution NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "s_sent1 ='There are no easy solution.' # First short sentence\n",
    "\n",
    "doc = nlp(s_sent1)\n",
    "# look at each work and break in each entity and PoS for entity\n",
    "for ent in doc:\n",
    "      print(ent, ent.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of Speech: [**('There', 'EX'), ('are', 'VBP'),** ('no', 'DT'), ('easy', 'JJ'), ('solution', 'NN'), ('.', '.')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few differences were observed highligted in bold. \n",
    "\n",
    "**There**: There was incorrectly classified by spacy as PRON and correctly done by nlkt as EX (Existential There)\n",
    "\n",
    "**are**: nltk has incorrectly classified are by VBP (verb, sing. present) and are is plural. However, spacy correcly categorized it AUX. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Sentence 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my DET\n",
      "cat NOUN\n",
      "is AUX\n",
      "pink ADJ\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "s_sent2 ='my cat is pink.'# Second short sentence\n",
    "# look at each work and break in each entity and PoS for entity\n",
    "doc = nlp(s_sent2)\n",
    "for ent in doc:\n",
    "      print(ent, ent.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of Speech in 2nd Sentence: [**('my', 'PRP$')**, ('cat', 'NN'), **('is', 'VBZ')**, ('pink', 'JJ'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoS differences were observed between nltk and spacy in 2rd short sentence and is highligted in bold above.\n",
    "\n",
    "**my:** my is inaccurately defined by spacy as DET and nltk correctly classified as possessive pronoun (PRP$)\n",
    "\n",
    "**is:** is can be defined as both AUX and VBZ. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Sentence 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color NOUN\n",
      "are AUX\n",
      "colorful ADJ\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "s_sent3 ='color are colorful.' # Third sentence\n",
    "# look at each work and break in each entity and PoS for entity\n",
    "doc = nlp(s_sent3)\n",
    "for ent in doc:\n",
    "      print(ent, ent.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of Speech: [('color', 'NN'), **('are', 'VBP')**, ('colorful', 'JJ'), ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoS difference was observed between nltk and spacy in 3rd short sentence and is highligted in bold above.\n",
    "\n",
    "**are:** spacy and nltk correctly classified as helping verb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Sentence 4¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET\n",
      "watch NOUN\n",
      "watches VERB\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "s_sent4 ='The watch watches.' # Fourth Sentence\n",
    "# look at each work and break in each entity and PoS for entity \n",
    "doc = nlp(s_sent4)\n",
    "for ent in doc:\n",
    "      print(ent, ent.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of Speech: [('The', 'DT'), ('watch', 'NN'), **('watches', 'NNS')**, ('.', '.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoS difference was observed between nltk and spacy in 4th short sentence and is highligted in bold above.\n",
    "\n",
    "**watches:** spacy correctly classified watches as verb by spacy and was incorrectly categorized as NNS (noun plural)by nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.\tIn a news article from this week’s news, find a random sentence of at least 10 words.\n",
    "#### a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence from News:\n",
    " \"A key Democratic senator says he will not vote for the largest overhaul of U.S. election law in at least a generation, leaving no plausible path forward for legislation that his party and the White House have portrayed as crucial for protecting access to the ballot.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[('A',DT), ('key',ADJ), ('Democratic',ADJ), ('senator', NN), ('says', VBZ), ('he',PRP), ('will',VB), ('not', DET), ('vote',VB), ('for',IN), ('the',DT), ('largest',ADJ), ('overhaul' NN), ('of',IN), ('U.S.', ADJ), ('election',ADJ), ('law',NN), ('in',IN), ('at',IN), ('least', JJS), ('a',DT), ('generation',NN)(',',,), ('leaving',VBG), ('no',DT) ('plausible',ADJ), ('path',NN), ('forward',ADJ), ('for',IN), ('legislation',NN), ('that', CC), ('his',POS), ('party',NN), ('and',CC), ('the',DT), ('White House',NNP), ('have',VB), ('portrayed',VBD), ('as',IN), ('crucial',ADJ), ('for',IN), ('protecting',VBG), ('access',NN), ('to',IN), ('the',DT), ('ballot',NN)('.',.)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=\"A key Democratic senator says he will not vote for the largest overhaul of U.S. election law in at least a generation, leaving no plausible path forward for legislation that his party and the White House have portrayed as crucial for protecting access to the ballot.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech: [('A', 'DT'), ('key', 'JJ'), ('Democratic', 'NNP'), ('senator', 'NN'), ('says', 'VBZ'), ('he', 'PRP'), ('will', 'MD'), ('not', 'RB'), ('vote', 'VB'), ('for', 'IN'), ('the', 'DT'), ('largest', 'JJS'), ('overhaul', 'NN'), ('of', 'IN'), ('U.S.', 'NNP'), ('election', 'NN'), ('law', 'NN'), ('in', 'IN'), ('at', 'IN'), ('least', 'JJS'), ('a', 'DT'), ('generation', 'NN'), (',', ','), ('leaving', 'VBG'), ('no', 'DT'), ('plausible', 'JJ'), ('path', 'NN'), ('forward', 'NN'), ('for', 'IN'), ('legislation', 'NN'), ('that', 'IN'), ('his', 'PRP$'), ('party', 'NN'), ('and', 'CC'), ('the', 'DT'), ('White', 'NNP'), ('House', 'NNP'), ('have', 'VBP'), ('portrayed', 'VBN'), ('as', 'IN'), ('crucial', 'JJ'), ('for', 'IN'), ('protecting', 'VBG'), ('access', 'NN'), ('to', 'TO'), ('the', 'DT'), ('ballot', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Find Part of Speach (PoS) using nltk\n",
    "import nltk # import nltk\n",
    "news_tokens = nltk.word_tokenize(news) # tokenize the sentence\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(news_tokens)) # find part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A DET\n",
      "key ADJ\n",
      "Democratic ADJ\n",
      "senator NOUN\n",
      "says VERB\n",
      "he PRON\n",
      "will VERB\n",
      "not PART\n",
      "vote VERB\n",
      "for ADP\n",
      "the DET\n",
      "largest ADJ\n",
      "overhaul NOUN\n",
      "of ADP\n",
      "U.S. PROPN\n",
      "election NOUN\n",
      "law NOUN\n",
      "in ADP\n",
      "at ADP\n",
      "least ADJ\n",
      "a DET\n",
      "generation NOUN\n",
      ", PUNCT\n",
      "leaving VERB\n",
      "no DET\n",
      "plausible ADJ\n",
      "path NOUN\n",
      "forward ADV\n",
      "for ADP\n",
      "legislation NOUN\n",
      "that SCONJ\n",
      "his DET\n",
      "party NOUN\n",
      "and CCONJ\n",
      "the DET\n",
      "White PROPN\n",
      "House PROPN\n",
      "have AUX\n",
      "portrayed VERB\n",
      "as SCONJ\n",
      "crucial ADJ\n",
      "for ADP\n",
      "protecting VERB\n",
      "access NOUN\n",
      "to ADP\n",
      "the DET\n",
      "ballot NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "#Find Part of Speach (POS) usig spacy\n",
    "\n",
    "# look at each work and break in each entity and PoS for entity \n",
    "doc = nlp(news)\n",
    "for ent in doc:\n",
    "      print(ent, ent.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neighter of the method match 100% compare to my manual method. However they are close. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.\tExplain any differences between the two taggers and your manual tagging as much as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual vs. nltk\n",
    "[('A',DT), ('key',ADJ), **('Democratic',ADJ)**, ('senator', NN), ('says', VBZ), ('he',PRP), **('will',VB)**, **('not', DET)**, ('vote',VB), ('for',IN), ('the',DT), ('largest',ADJ), ('overhaul' NN), ('of',IN), **('U.S.', ADJ)**, **('election',ADJ)**, ('law',NN), ('in',IN), ('at',IN), ('least', JJS), ('a',DT), ('generation',NN)(',',,), ('leaving',VBG), ('no',DT) ('plausible',ADJ), ('path',NN), **('forward',ADJ)**, ('for',IN), ('legislation',NN), **('that', CC)**, ('his',PRP$), ('party',NN), ('and',CC), ('the',DT), ('White House',NNP), **('have',VB)**, ('portrayed',VBD), ('as',IN), ('crucial',ADJ), ('for',IN), ('protecting',VBG), ('access',NN), ('to',IN), ('the',DT), ('ballot',NN)('.',.)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual vs spacy\n",
    "[('A',DT), ('key',ADJ), ('Democratic',ADJ), ('senator', NN), ('says', VBZ), **('he',PRP)**, ('will',VB), **('not', DET)**, ('vote',VB), **('for',IN)**, ('the',DT), ('largest',ADJ), ('overhaul' NN), **('of',IN)**, **('U.S.', ADJ)*, **('election',ADJ)**, ('law',NN), **('in',IN)**, **('at',IN)**, ('least', JJS), ('a',DT), ('generation',NN)(',',,), ('leaving',VBG), ('no',DT) ('plausible',ADJ), ('path',NN), **('forward',ADJ)**, **('for',IN)**, ('legislation',NN), ('that', CC), **('his',POS)**, ('party',NN), ('and',CC), ('the',DT), **('White House',NNP)**, **('have',VB)**, ('portrayed',VBD), **('as',IN)**, ('crucial',ADJ), ('for',IN), ('protecting',VBG), ('access',NN), **('to',IN)**, ('the',DT), ('ballot',NN)('.',.)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Both the methods classified the words correctly in most of the cases. As the sentence is very long and complex, it can become challenging to accurately predict the Part of Speech (PoS). I think we have to be ready to accept some level of error. These errors will depend on the complexity of the sentence. Even the specialist align only in 93% of cases. nltk and spacy use different algorithms to identify Part of Speech classification. Both the method may see the same or similar requests but may vary drastically. nltk vs. manual comparison show 18% (8/44) error, and manual vs. spacy shows 31.8% (14/44) error. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
